# -*- coding: utf-8 -*-
"""employee_attrition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oxGgp5XV1sGvGoGQV8mSVYWgQZmAcvXF
"""

import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

import pandas as pd

# Read the HR employee attrition dataset from a CSV file
df = pd.read_csv('HR-Employee-Attrition.csv')

# Display the first few rows of the DataFrame
df.head()

df.tail()

df.shape

df.columns

df.duplicated().sum()

df.isnull().sum()

df.info()

df.describe()

df.nunique()

# Create a new DataFrame `df_new` by selecting specific columns from `df`
df_new = df[['BusinessTravel', 'Department', 'Education', 'EducationField',
             'EnvironmentSatisfaction', 'Gender', 'JobInvolvement', 'JobRole',
             'JobSatisfaction', 'MaritalStatus', 'NumCompaniesWorked', 'OverTime',
             'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel',
             'TrainingTimesLastYear', 'WorkLifeBalance', 'Attrition']]

# Iterate over each column in `df_new`
for i in df_new.columns:
    print(i, ':')

    # Print the unique values in the column
    print('Unique Values:', df_new[i].unique())

    # Print the value counts for each unique value in the column
    print('Value Counts:')
    print(df_new[i].value_counts())

    print('\n')

# Iterate over each column in `df_new`
for i in df_new.columns:
    plt.figure(figsize=[15, 7])

    # Print the column name for the countplot
    print('Countplot for:', i)

    # Create a countplot using seaborn
    sns.countplot(x=i, data=df_new, palette='hls')

    # Rotate x-axis labels if necessary
    plt.xticks(rotation=0)

    # Display the plot
    plt.show()

    print('\n')

# Iterate over each column in `df_new`
for i in df_new.columns:
    plt.figure(figsize=[15, 7])

    # Print the column name for the pie plot
    print('Pie plot for:', i)

    # Create a pie plot using value counts from the column
    df_new[i].value_counts().plot(kind='pie', autopct='%1.1f%%')

    # Display the plot
    plt.show()

    print('\n')

# Find columns with integer data type
int_cols = [col for col in df.columns if df[col].dtype == 'int64']
print('Integer columns:', int_cols)
print('\n')

# Find columns with object (string) data type
obj_cols = [col for col in df.columns if df[col].dtype == 'object']
print('Object columns:', obj_cols)

# Create a figure with a specified size of 15x7
plt.figure(figsize=[15, 7])

# Create a histogram plot using seaborn
sns.histplot(df['Age'], kde='True', bins=5, palette='hls')

# Rotate x-axis labels if necessary
plt.xticks(rotation=0)

# Display the plot
plt.show()

import plotly.express as px

# Create a box plot using plotly express
fig = px.box(df, x='Attrition', y='Age')

# Display the plot
fig.show()

# Create a box plot using plotly express
fig = px.box(df, x='Attrition', y='DailyRate')

# Display the plot
fig.show()

# Create a box plot using plotly express
fig = px.box(df, x='Attrition', y='DistanceFromHome')

# Display the plot
fig.show()

# Create a box plot using plotly express
fig = px.box(df, x='Attrition', y='Education')

# Display the plot
fig.show()

fig = px.box(df, x = 'Attrition', y = 'EnvironmentSatisfaction')
fig.show()

fig = px.box(df, x = 'Attrition', y = 'JobLevel')
fig.show()

fig = px.box(df, x = 'Attrition', y = 'JobSatisfaction')
fig.show()

fig = px.box(df, x = 'Attrition', y = 'MonthlyIncome')
fig.show()

fig = px.box(df, x = 'Attrition', y = 'PercentSalaryHike')
fig.show()

fig = px.box(df, x = 'Attrition', y = 'RelationshipSatisfaction')
fig.show()

fig = px.box(df, x = 'Attrition', y = 'TotalWorkingYears')
fig.show()

fig = px.box(df, x = 'Attrition', y = 'WorkLifeBalance')
fig.show()

fig = px.box(df, x = 'Attrition', y = 'YearsAtCompany')
fig.show()

fig = px.box(df, x = 'Attrition', y = 'YearsInCurrentRole')
fig.show()

fig = px.box(df, x = 'Attrition', y = 'YearsSinceLastPromotion')
fig.show()

fig = px.box(df, x = 'Attrition', y = 'YearsWithCurrManager')
fig.show()

from sklearn.preprocessing import LabelEncoder

# Create an instance of LabelEncoder
le = LabelEncoder()

# Encode the 'BusinessTravel' column
df['BusinessTravel'] = le.fit_transform(df['BusinessTravel'])

# Encode the 'Department' column
df['Department'] = le.fit_transform(df['Department'])

# Encode the 'EducationField' column
df['EducationField'] = le.fit_transform(df['EducationField'])

# Encode the 'JobRole' column
df['JobRole'] = le.fit_transform(df['JobRole'])

# Encode the 'Gender' column
df['Gender'] = le.fit_transform(df['Gender'])

# Encode the 'MaritalStatus' column
df['MaritalStatus'] = le.fit_transform(df['MaritalStatus'])

# Encode the 'Over18' column
df['Over18'] = le.fit_transform(df['Over18'])

# Encode the 'OverTime' column
df['OverTime'] = le.fit_transform(df['OverTime'])

# Display the updated DataFrame
df.head()

# Calculate the correlation matrix
corr_matrix = df.corr()
corr_matrix

# Create a heatmap of the correlation matrix
plt.figure(figsize=[30,20],)
sns.heatmap(corr_matrix, annot = True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

# creates a copy of the DataFrame
df1 = df.copy()

X = df1.drop(['Attrition'], axis = 1)
y = df1['Attrition']

from sklearn import preprocessing

# Create an instance of StandardScaler
scaler = preprocessing.StandardScaler()

# Perform standardization on the feature data in X
X = scaler.fit_transform(X)

from sklearn.ensemble import ExtraTreesClassifier
import matplotlib.pyplot as plt

# Create an instance of ExtraTreesClassifier
model = ExtraTreesClassifier()

# Train the model on the standardized feature data X and target variable y
model.fit(X, y)

# Print the feature importances
print(model.feature_importances_)

X1 = df1.iloc[:,:-1]
X1.head()

feat_importances = pd.Series(model.feature_importances_, index=X1.columns)
feat_importances.nlargest(20).plot(kind='barh')
plt.show()

X_new = X1[['StockOptionLevel', 'MonthlyIncome', 'JobInvolvement', 'OverTime',
 'Age', 'YearsAtCompany', 'JobRole', 'HourlyRate', 'BusinessTravel', 'PerformanceRating',
 'StandardHours', 'MonthlyRate', 'JobLevel', 'Department', 'JobSatisfaction', 'YearsSinceLastPromotion',
 'WorkLifeBalance', 'MaritalStatus', 'Over18']]

X_new.shape

y.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test= train_test_split(X_new, y, test_size= 0.30, random_state=0)

from sklearn.linear_model import LogisticRegression
log_r= LogisticRegression(random_state=0)
log_r.fit(X_train, y_train)

y_pred_lr= log_r.predict(X_test)

from sklearn.metrics import accuracy_score
accuracy_score(y_test, y_pred_lr)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred_lr)
cm

plt.figure(figsize=[10,7],)
sns.heatmap(cm, annot = True, cmap='coolwarm')
plt.show()

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred_lr))

from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)

y_pred_dt= dt.predict(X_test)

accuracy_score(y_test, y_pred_dt)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred_dt)
cm

plt.figure(figsize=[10,7],)
sns.heatmap(cm, annot = True, cmap='coolwarm')
plt.show()

print(classification_report(y_test, y_pred_dt))

from sklearn.ensemble import RandomForestClassifier
rf_c = RandomForestClassifier(n_estimators= 10, criterion="entropy")
rf_c.fit(X_train, y_train)

y_pred_rf_c= rf_c.predict(X_test)

accuracy_score(y_test, y_pred_rf_c)

cm= confusion_matrix(y_test, y_pred_rf_c)
cm

plt.figure(figsize=[10,7],)
sns.heatmap(cm, annot = True)
plt.show()

print(classification_report(y_test, y_pred_rf_c))

from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV

folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 40)

def grid_search(model,folds,params,scoring):
  grid_search = GridSearchCV(model,
  cv = folds,
  param_grid = params,
  scoring = scoring,
  n_jobs = -1, verbose = 1)
  return grid_search

def print_best_score_params(model):
 print("Best Score: ", model.best_score_)
 print("Best Hyperparameters: ", model.best_params_)

log_reg = LogisticRegression()
log_params = {'C': [0.01, 1, 10],
 'penalty': ['l1', 'l2'],
 'solver': ['liblinear','newton-cg','saga']
 }
grid_search_log = grid_search(log_reg, folds, log_params, scoring=None)
grid_search_log.fit(X_train, y_train)
print_best_score_params(grid_search_log)

dtc = DecisionTreeClassifier(random_state=40)
dtc_params = {
 'max_depth': [5,10,20,30],
 'min_samples_leaf': [5,10,20,30]
}
grid_search_dtc = grid_search(dtc, folds, dtc_params, scoring='roc_auc_ovr')
grid_search_dtc.fit(X_train, y_train)
print_best_score_params(grid_search_dtc)

rfc = RandomForestClassifier(random_state=40, n_jobs = -1,oob_score=True)
rfc_params = {'max_depth': [10,20,30,40],
 'min_samples_leaf': [5,10,15,20,30],
 'n_estimators': [100,200,500,700]
 }
grid_search_rfc = grid_search(rfc, folds, rfc_params, scoring='roc_auc_ovr')
grid_search_rfc.fit(X_train, y_train)
print('OOB SCORE :',grid_search_rfc.best_estimator_.oob_score_)

import pandas as pd
from sklearn.preprocessing import LabelEncoder
from keras.models import Sequential
from keras.layers import Dense

# Assuming y_train is a pandas Series containing the target variable
print(y_train.unique())  # Check unique values in y_train

# Use LabelEncoder to encode the target variable
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)

# Create the model
model = Sequential()
model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Fit the model with the updated target variable
model.fit(X_train, y_train_encoded, epochs=50, batch_size=32)

# Encode the target variable for the test set
y_test_encoded = label_encoder.transform(y_test)

# Evaluate the model on the test data
test_loss, test_acc = model.evaluate(X_test, y_test_encoded)
print('Test loss:', test_loss)
print('Test accuracy:', test_acc)

df2 = pd.read_csv('HR-Employee-Attrition.csv')

df2['BusinessTravel'] = le.fit_transform(df2['BusinessTravel'])
df2['Department'] = le.fit_transform(df2['Department'])
df2['EducationField'] = le.fit_transform(df2['EducationField'])
df2['JobRole'] = le.fit_transform(df2['JobRole'])
df2['Gender'] = le.fit_transform(df2['Gender'])
df2['MaritalStatus'] = le.fit_transform(df2['MaritalStatus'])
df2['Over18'] = le.fit_transform(df2['Over18'])
df2['OverTime'] = le.fit_transform(df2['OverTime'])

X_new1 = df2[['StockOptionLevel', 'MonthlyIncome', 'JobInvolvement', 'OverTime',
 'Age', 'YearsAtCompany', 'JobRole', 'HourlyRate', 'BusinessTravel', 'PerformanceRating',
 'StandardHours', 'MonthlyRate', 'JobLevel', 'Department', 'JobSatisfaction', 'YearsSinceLastPromotion',
 'WorkLifeBalance', 'MaritalStatus', 'Over18']]

X2 = scaler.fit_transform(X_new1)

y_lr = grid_search_log.predict(X2)
y_lr

y_dt = grid_search_dtc.predict(X_new1)
y_dt

y_rfc = grid_search_rfc.predict(X_new1)
y_rfc

y_nn = model.predict(X_new1)
y_nn